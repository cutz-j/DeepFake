{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Input, Dense, Flatten, GlobalAveragePooling2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, Lambda\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 1  # number of classes\n",
    "img_width, img_height = 224, 224  # change based on the shape/structure of your images\n",
    "batch_size = 32  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU/GPU memory capacity (powers of 2 values).\n",
    "nb_epoch = 50  # number of iteration the algorithm gets trained.\n",
    "learn_rate = 1e-5  # sgd learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIR ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'd:/data/preprocessed_dataset/train'\n",
    "validation_dir = 'd:/data/preprocessed_dataset/validation'\n",
    "test50_dir = 'd:/data/preprocessed_dataset/test50'\n",
    "test75_dir = 'd:/data/preprocessed_dataset/test75'\n",
    "test95_dir = 'd:/data/preprocessed_dataset/test95'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 96)        34848     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 56, 56, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 256)       614400    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 27, 27, 384)       884736    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 27, 27, 384)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 384)       1327104   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 256)       884736    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 4097      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,802,593\n",
      "Trainable params: 4,802,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "img_input = Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "x = Conv2D(96, 11, strides=4, padding='same', use_bias=False)(img_input) # 15\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(256, 5, strides=1, padding='same', use_bias=False)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=3, strides=2, padding='valid')(x) # 8\n",
    "\n",
    "x = Conv2D(384, 3, strides=1, padding='same', use_bias=False)(x) # 15\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=3, strides=2, padding='valid')(x) # 8\n",
    "\n",
    "x = Conv2D(384, 3, strides=1, padding='same', use_bias=False)(x) # 15\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(256, 3, strides=1, padding='same', use_bias=False)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "model_out = MaxPooling2D(pool_size=3, strides=2, padding='valid')(x) # 8\n",
    "# Add fully connected layer\n",
    "x = GlobalAveragePooling2D()(model_out)\n",
    "x = Dense(4096, activation=None)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(1, activation=None)(x)\n",
    "out = Activation('sigmoid')(x)\n",
    "\n",
    "model = Model(img_input, out)\n",
    "print(model.summary())\n",
    "print(len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(lr=learn_rate),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(directory, batch_size=32):\n",
    "    folder =  np.sort(os.listdir(directory))\n",
    "    real_img = np.asarray(glob.glob(directory + '/' + folder[0]+'/*.png'))\n",
    "    real_idx = np.arange(len(real_img))\n",
    "    \n",
    "    while 1:\n",
    "        X1 = []\n",
    "        X2 = []\n",
    "        y = []\n",
    "        \n",
    "        if (len(real_idx) < batch_size):\n",
    "            real_idx = np.arange(len(real_img))\n",
    "            continue\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            if (len(real_idx) < batch_size):\n",
    "                real_idx = np.arange(len(real_img))\n",
    "                break\n",
    "            random1 = np.random.choice(real_idx, 1, replace=False)\n",
    "            real_idx = real_idx[~np.isin(real_idx, random1)]\n",
    "            random2 = np.random.choice(real_idx, 1, replace=False)\n",
    "            real_idx = real_idx[~np.isin(real_idx, random2)]\n",
    "            X1.append(np.asarray(Image.open(real_img[random1[0]]).convert(\"RGB\"))/255.)\n",
    "            X2.append(np.asarray(Image.open(real_img[random2[0]]).convert(\"RGB\"))/255.)\n",
    "            y.append(np.array([0.]))\n",
    "\n",
    "        X1 = np.asarray(X1)\n",
    "        X2 = np.asarray(X2)\n",
    "        y = np.asarray(y)\n",
    "        yield [X1, X2], y\n",
    "        \n",
    "def generator_res(ft_dir, directory, batch_size=1, critical_value=0.5):\n",
    "    folder = np.sort(os.listdir(directory))\n",
    "    ft_img = np.asarray(glob.glob(ft_dir + '/' + '0' +'/*.png'))\n",
    "    ft_idx = np.arange(len(ft_img))\n",
    "    random1 = np.random.choice(ft_idx, 1, replace=False)\n",
    "    img = np.asarray(Image.open(ft_img[random1[0]]).convert(\"RGB\"))/255.\n",
    "    fake_img = np.asarray(glob.glob(directory + '/' + folder[1] + '/*.png'))\n",
    "    fake_idx = np.arange(len(fake_img))\n",
    "    real_img = np.asarray(glob.glob(directory + '/' + folder[0] + '/*.png'))\n",
    "    real_idx = np.arange(len(real_img))\n",
    "    while 1:\n",
    "        X1 = []\n",
    "        X2 = []\n",
    "        y = []\n",
    "        if (len(fake_idx) < batch_size):\n",
    "            break\n",
    "        if (len(real_idx) < batch_size):\n",
    "            break\n",
    "        for _ in range(batch_size):\n",
    "            if np.random.uniform() > critical_value:\n",
    "                if (len(fake_idx) < batch_size):\n",
    "                    break\n",
    "                random2 = np.random.choice(fake_idx, 1, replace=False)\n",
    "                fake_idx = fake_idx[~np.isin(fake_idx, random2)]\n",
    "                X1.append(img)\n",
    "                X2.append(np.asarray(Image.open(fake_img[random2[0]]).convert(\"RGB\"))/255.)\n",
    "                y.append(np.array([1.]))\n",
    "            else:\n",
    "                if (len(real_idx) < batch_size):\n",
    "                    break\n",
    "                random3 = np.random.choice(real_idx, 1, replace=False)\n",
    "                real_idx = real_idx[~np.isin(real_idx, random3)]\n",
    "                X1.append(img)\n",
    "                X2.append(np.asarray(Image.open(real_img[random3[0]]).convert(\"RGB\"))/255.)\n",
    "                y.append(np.array([0.]))\n",
    "        X1 = np.asarray(X1)\n",
    "        X2 = np.asarray(X2)\n",
    "        y = np.asarray(y)\n",
    "        yield [X1, X2], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manDist(x):\n",
    "    result = K.exp(-K.sum(K.abs(x[0] - x[1]), axis=1, keepdims=True))\n",
    "    return result\n",
    "\n",
    "def euclidean_distance(inputs):\n",
    "    assert len(inputs) == 2, 'Euclidean distance needs 2 inputs, %d given' % len(inputs)\n",
    "    u, v = inputs\n",
    "    return K.sqrt(K.sum((K.square(u - v + 1e-7)), axis=1, keepdims=True))  \n",
    "\n",
    "def contrastive_loss(y_true,y_pred):\n",
    "    margin=1.4\n",
    "    return K.mean((1. - y_true) * K.square(y_pred) + y_true * K.square(K.maximum(margin - y_pred, 0.)))\n",
    "\n",
    "def siamese_acc(y_true, y_pred):\n",
    "    return K.mean((K.equal(y_true, K.cast(y_pred > 0.4, K.floatx()))), axis=1)\n",
    "\n",
    "def y_pred_prt(y_true, y_pred):\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 251702 images belonging to 2 classes.\n",
      "Found 28298 images belonging to 2 classes.\n",
      "Found 33086 images belonging to 2 classes.\n",
      "Found 21866 images belonging to 2 classes.\n",
      "Found 17480 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(img_height, img_width),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size=(img_height, img_width),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        class_mode='binary')\n",
    "\n",
    "test50_generator = test_datagen.flow_from_directory(test50_dir,\n",
    "                                                  target_size=(img_height, img_width),\n",
    "                                                  batch_size=32,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode='binary')\n",
    "\n",
    "test75_generator = test_datagen.flow_from_directory(test75_dir,\n",
    "                                                  target_size=(img_height, img_width),\n",
    "                                                  batch_size=32,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode='binary')\n",
    "\n",
    "test95_generator = test_datagen.flow_from_directory(test95_dir,\n",
    "                                                  target_size=(img_height, img_width),\n",
    "                                                  batch_size=32,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "  6/100 [>.............................] - ETA: 14:37 - loss: 0.6938 - acc: 0.31 - ETA: 7:18 - loss: 0.6934 - acc: 0.5156 - ETA: 4:51 - loss: 0.6932 - acc: 0.520 - ETA: 4:01 - loss: 0.6932 - acc: 0.515 - ETA: 3:54 - loss: 0.6933 - acc: 0.493 - ETA: 3:48 - loss: 0.6931 - acc: 0.5052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.100943). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7/100 [=>............................] - ETA: 3:45 - loss: 0.6930 - acc: 0.5045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.197887). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9/100 [=>............................] - ETA: 3:42 - loss: 0.6929 - acc: 0.503 - ETA: 3:36 - loss: 0.6928 - acc: 0.5243"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.197888). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/100 [==>...........................] - ETA: 3:27 - loss: 0.6927 - acc: 0.543 - ETA: 3:20 - loss: 0.6926 - acc: 0.5682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.205383). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12/100 [==>...........................] - ETA: 3:12 - loss: 0.6925 - acc: 0.5859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.214886). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14/100 [===>..........................] - ETA: 3:07 - loss: 0.6924 - acc: 0.593 - ETA: 3:01 - loss: 0.6923 - acc: 0.6004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.219883). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21/100 [=====>........................] - ETA: 2:57 - loss: 0.6922 - acc: 0.593 - ETA: 2:53 - loss: 0.6922 - acc: 0.584 - ETA: 2:49 - loss: 0.6921 - acc: 0.599 - ETA: 2:46 - loss: 0.6920 - acc: 0.611 - ETA: 2:42 - loss: 0.6919 - acc: 0.629 - ETA: 2:39 - loss: 0.6917 - acc: 0.648 - ETA: 2:36 - loss: 0.6915 - acc: 0.6637"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.215386). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22/100 [=====>........................] - ETA: 2:32 - loss: 0.6915 - acc: 0.6690"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.213895). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23/100 [=====>........................] - ETA: 2:30 - loss: 0.6914 - acc: 0.6671"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.221382). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24/100 [======>.......................] - ETA: 2:26 - loss: 0.6913 - acc: 0.6628"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.222382). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25/100 [======>.......................] - ETA: 2:23 - loss: 0.6912 - acc: 0.6587"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.220392). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27/100 [=======>......................] - ETA: 2:21 - loss: 0.6911 - acc: 0.650 - ETA: 2:18 - loss: 0.6910 - acc: 0.6493"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.213887). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31/100 [========>.....................] - ETA: 2:16 - loss: 0.6908 - acc: 0.646 - ETA: 2:13 - loss: 0.6906 - acc: 0.645 - ETA: 2:11 - loss: 0.6901 - acc: 0.649 - ETA: 2:08 - loss: 0.6901 - acc: 0.6431"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.219884). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/100 [========>.....................] - ETA: 2:06 - loss: 0.6898 - acc: 0.6406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.220384). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35/100 [=========>....................] - ETA: 2:04 - loss: 0.6901 - acc: 0.629 - ETA: 2:02 - loss: 0.6900 - acc: 0.625 - ETA: 1:59 - loss: 0.6897 - acc: 0.6241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.204885). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36/100 [=========>....................] - ETA: 1:58 - loss: 0.6892 - acc: 0.6259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.228870). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37/100 [==========>...................] - ETA: 1:56 - loss: 0.6891 - acc: 0.6216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.208881). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38/100 [==========>...................] - ETA: 1:54 - loss: 0.6891 - acc: 0.6151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.217377). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39/100 [==========>...................] - ETA: 1:52 - loss: 0.6888 - acc: 0.6138"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.225372). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40/100 [===========>..................] - ETA: 1:50 - loss: 0.6889 - acc: 0.6062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.226871). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41/100 [===========>..................] - ETA: 1:48 - loss: 0.6886 - acc: 0.6044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.214378). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43/100 [===========>..................] - ETA: 1:46 - loss: 0.6884 - acc: 0.601 - ETA: 1:44 - loss: 0.6883 - acc: 0.5967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.207882). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44/100 [============>.................] - ETA: 1:42 - loss: 0.6882 - acc: 0.5930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.200386). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54/100 [===============>..............] - ETA: 1:40 - loss: 0.6877 - acc: 0.595 - ETA: 1:38 - loss: 0.6875 - acc: 0.591 - ETA: 1:36 - loss: 0.6873 - acc: 0.588 - ETA: 1:35 - loss: 0.6870 - acc: 0.587 - ETA: 1:33 - loss: 0.6869 - acc: 0.584 - ETA: 1:31 - loss: 0.6866 - acc: 0.581 - ETA: 1:29 - loss: 0.6866 - acc: 0.578 - ETA: 1:27 - loss: 0.6863 - acc: 0.576 - ETA: 1:25 - loss: 0.6859 - acc: 0.575 - ETA: 1:23 - loss: 0.6854 - acc: 0.5741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.203384). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56/100 [===============>..............] - ETA: 1:22 - loss: 0.6848 - acc: 0.576 - ETA: 1:20 - loss: 0.6843 - acc: 0.5776"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.214878). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 59/100 [================>.............] - ETA: 1:18 - loss: 0.6838 - acc: 0.577 - ETA: 1:16 - loss: 0.6834 - acc: 0.576 - ETA: 1:14 - loss: 0.6828 - acc: 0.5757"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.215877). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60/100 [=================>............] - ETA: 1:12 - loss: 0.6825 - acc: 0.5740"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.231868). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65/100 [==================>...........] - ETA: 1:10 - loss: 0.6818 - acc: 0.573 - ETA: 1:09 - loss: 0.6814 - acc: 0.573 - ETA: 1:07 - loss: 0.6811 - acc: 0.570 - ETA: 1:05 - loss: 0.6799 - acc: 0.573 - ETA: 1:03 - loss: 0.6795 - acc: 0.5721"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.221374). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 68/100 [===================>..........] - ETA: 1:01 - loss: 0.6785 - acc: 0.572 - ETA: 59s - loss: 0.6780 - acc: 0.570 - ETA: 58s - loss: 0.6776 - acc: 0.5689"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.219378). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69/100 [===================>..........] - ETA: 56s - loss: 0.6773 - acc: 0.5666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.195894). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70/100 [====================>.........] - ETA: 54s - loss: 0.6765 - acc: 0.5670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.184900). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 71/100 [====================>.........] - ETA: 52s - loss: 0.6759 - acc: 0.5682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.192395). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75/100 [=====================>........] - ETA: 50s - loss: 0.6748 - acc: 0.56 - ETA: 48s - loss: 0.6736 - acc: 0.57 - ETA: 47s - loss: 0.6731 - acc: 0.57 - ETA: 45s - loss: 0.6722 - acc: 0.5696"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.208380). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76/100 [=====================>........] - ETA: 43s - loss: 0.6719 - acc: 0.5670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.187393). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78/100 [======================>.......] - ETA: 41s - loss: 0.6716 - acc: 0.56 - ETA: 39s - loss: 0.6712 - acc: 0.5629"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.202384). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 81/100 [=======================>......] - ETA: 37s - loss: 0.6705 - acc: 0.56 - ETA: 36s - loss: 0.6698 - acc: 0.56 - ETA: 34s - loss: 0.6692 - acc: 0.5741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.218384). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84/100 [========================>.....] - ETA: 32s - loss: 0.6686 - acc: 0.57 - ETA: 30s - loss: 0.6678 - acc: 0.58 - ETA: 28s - loss: 0.6668 - acc: 0.5874"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.216388). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85/100 [========================>.....] - ETA: 27s - loss: 0.6660 - acc: 0.5923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.212387). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90/100 [==========================>...] - ETA: 25s - loss: 0.6652 - acc: 0.59 - ETA: 23s - loss: 0.6638 - acc: 0.59 - ETA: 21s - loss: 0.6633 - acc: 0.59 - ETA: 19s - loss: 0.6619 - acc: 0.59 - ETA: 18s - loss: 0.6606 - acc: 0.5962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.225375). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92/100 [==========================>...] - ETA: 16s - loss: 0.6589 - acc: 0.59 - ETA: 14s - loss: 0.6574 - acc: 0.6012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.228382). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96/100 [===========================>..] - ETA: 12s - loss: 0.6565 - acc: 0.60 - ETA: 10s - loss: 0.6551 - acc: 0.60 - ETA: 8s - loss: 0.6540 - acc: 0.6112 - ETA: 7s - loss: 0.6526 - acc: 0.6149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.238873). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97/100 [============================>.] - ETA: 5s - loss: 0.6507 - acc: 0.6186"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.232868). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98/100 [============================>.] - ETA: 3s - loss: 0.6494 - acc: 0.6215"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.223873). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/100 [============================>.] - ETA: 1s - loss: 0.6479 - acc: 0.6247"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.205890). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    }
   ],
   "source": [
    "callback_list = [EarlyStopping(monitor='val_acc', patience=5),\n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)]\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=100,\n",
    "                            epochs=20,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=len(validation_generator),\n",
    "                            callbacks=callback_list,\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_dir = 'd:/data/preprocessed_dataset/fine-tune'\n",
    "train_gen = generator(ft_dir)\n",
    "test50_gen = generator_res(ft_dir, test50_dir, batch_size=1, critical_value=0.5)\n",
    "test75_gen = generator_res(ft_dir, test75_dir, batch_size=1, critical_value=0.75)\n",
    "test95_gen = generator_res(ft_dir, test95_dir, batch_size=1, critical_value=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test50_classes = test50_generator.classes\n",
    "print(\"50% \", len(test50_classes[test50_classes == 1]))\n",
    "test75_classes = test75_generator.classes\n",
    "print(\"75% \", len(test75_classes[test75_classes == 1]))\n",
    "test95_classes = test95_generator.classes\n",
    "print(\"95%: \", len(test95_classes[test95_classes == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"d:/data/preprocessed_dataset/fake_alexnet.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 1)                 4802593   \n",
      "=================================================================\n",
      "Total params: 4,802,593\n",
      "Trainable params: 4,097\n",
      "Non-trainable params: 4,798,496\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 1)            4802593     input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           model_3[1][0]                    \n",
      "                                                                 model_3[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,802,593\n",
      "Trainable params: 4,097\n",
      "Non-trainable params: 4,798,496\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - ETA: 2:27 - loss: 0.1394 - acc: 0.843 - ETA: 1:13 - loss: 0.1458 - acc: 0.828 - ETA: 49s - loss: 0.1173 - acc: 0.864 - ETA: 36s - loss: 0.0977 - acc: 0.89 - ETA: 29s - loss: 0.1007 - acc: 0.88 - ETA: 24s - loss: 0.1023 - acc: 0.87 - ETA: 20s - loss: 0.0949 - acc: 0.88 - ETA: 17s - loss: 0.0927 - acc: 0.88 - ETA: 15s - loss: 0.0929 - acc: 0.88 - ETA: 13s - loss: 0.0898 - acc: 0.89 - ETA: 12s - loss: 0.0908 - acc: 0.88 - ETA: 11s - loss: 0.0884 - acc: 0.89 - ETA: 10s - loss: 0.0912 - acc: 0.88 - ETA: 9s - loss: 0.0939 - acc: 0.8884 - ETA: 8s - loss: 0.0951 - acc: 0.887 - ETA: 7s - loss: 0.0971 - acc: 0.884 - ETA: 7s - loss: 0.0978 - acc: 0.884 - ETA: 7s - loss: 0.1055 - acc: 0.874 - ETA: 6s - loss: 0.1091 - acc: 0.870 - ETA: 6s - loss: 0.1135 - acc: 0.866 - ETA: 5s - loss: 0.1110 - acc: 0.866 - ETA: 5s - loss: 0.1133 - acc: 0.864 - ETA: 5s - loss: 0.1136 - acc: 0.863 - ETA: 4s - loss: 0.1125 - acc: 0.865 - ETA: 4s - loss: 0.1106 - acc: 0.868 - ETA: 4s - loss: 0.1087 - acc: 0.870 - ETA: 3s - loss: 0.1080 - acc: 0.872 - ETA: 3s - loss: 0.1080 - acc: 0.872 - ETA: 3s - loss: 0.1064 - acc: 0.874 - ETA: 2s - loss: 0.1063 - acc: 0.873 - ETA: 2s - loss: 0.1068 - acc: 0.872 - ETA: 2s - loss: 0.1056 - acc: 0.874 - ETA: 1s - loss: 0.1050 - acc: 0.874 - ETA: 1s - loss: 0.1027 - acc: 0.877 - ETA: 1s - loss: 0.1009 - acc: 0.878 - ETA: 1s - loss: 0.0994 - acc: 0.879 - ETA: 0s - loss: 0.0983 - acc: 0.881 - ETA: 0s - loss: 0.0971 - acc: 0.882 - ETA: 0s - loss: 0.0956 - acc: 0.884 - 11s 269ms/step - loss: 0.0943 - acc: 0.8862\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - ETA: 9s - loss: 0.1021 - acc: 0.875 - ETA: 9s - loss: 0.1111 - acc: 0.859 - ETA: 8s - loss: 0.1064 - acc: 0.864 - ETA: 8s - loss: 0.1063 - acc: 0.867 - ETA: 8s - loss: 0.0979 - acc: 0.875 - ETA: 8s - loss: 0.1174 - acc: 0.859 - ETA: 8s - loss: 0.1238 - acc: 0.843 - ETA: 7s - loss: 0.1219 - acc: 0.847 - ETA: 7s - loss: 0.1180 - acc: 0.850 - ETA: 7s - loss: 0.1125 - acc: 0.859 - ETA: 7s - loss: 0.1125 - acc: 0.858 - ETA: 6s - loss: 0.1168 - acc: 0.854 - ETA: 6s - loss: 0.1166 - acc: 0.853 - ETA: 5s - loss: 0.1089 - acc: 0.863 - ETA: 5s - loss: 0.1027 - acc: 0.872 - ETA: 5s - loss: 0.1057 - acc: 0.865 - ETA: 5s - loss: 0.1023 - acc: 0.869 - ETA: 5s - loss: 0.0994 - acc: 0.873 - ETA: 4s - loss: 0.1065 - acc: 0.865 - ETA: 4s - loss: 0.1061 - acc: 0.867 - ETA: 4s - loss: 0.1057 - acc: 0.867 - ETA: 4s - loss: 0.1082 - acc: 0.865 - ETA: 4s - loss: 0.1045 - acc: 0.869 - ETA: 3s - loss: 0.1055 - acc: 0.868 - ETA: 3s - loss: 0.1040 - acc: 0.870 - ETA: 3s - loss: 0.1058 - acc: 0.869 - ETA: 3s - loss: 0.1042 - acc: 0.871 - ETA: 2s - loss: 0.1017 - acc: 0.875 - ETA: 2s - loss: 0.1022 - acc: 0.873 - ETA: 2s - loss: 0.1029 - acc: 0.872 - ETA: 2s - loss: 0.1032 - acc: 0.873 - ETA: 1s - loss: 0.1028 - acc: 0.873 - ETA: 1s - loss: 0.1016 - acc: 0.874 - ETA: 1s - loss: 0.0992 - acc: 0.877 - ETA: 1s - loss: 0.0992 - acc: 0.877 - ETA: 0s - loss: 0.0993 - acc: 0.876 - ETA: 0s - loss: 0.0973 - acc: 0.879 - ETA: 0s - loss: 0.0969 - acc: 0.879 - ETA: 0s - loss: 0.0960 - acc: 0.881 - 9s 237ms/step - loss: 0.0945 - acc: 0.8834\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - ETA: 9s - loss: 0.0698 - acc: 0.937 - ETA: 9s - loss: 0.0879 - acc: 0.906 - ETA: 9s - loss: 0.0805 - acc: 0.906 - ETA: 9s - loss: 0.0771 - acc: 0.906 - ETA: 9s - loss: 0.0904 - acc: 0.887 - ETA: 8s - loss: 0.0958 - acc: 0.880 - ETA: 8s - loss: 0.1024 - acc: 0.875 - ETA: 8s - loss: 0.1036 - acc: 0.871 - ETA: 7s - loss: 0.1070 - acc: 0.868 - ETA: 6s - loss: 0.1153 - acc: 0.861 - ETA: 6s - loss: 0.1095 - acc: 0.868 - ETA: 6s - loss: 0.1055 - acc: 0.874 - ETA: 6s - loss: 0.1059 - acc: 0.871 - ETA: 6s - loss: 0.0995 - acc: 0.878 - ETA: 5s - loss: 0.0985 - acc: 0.878 - ETA: 5s - loss: 0.1025 - acc: 0.874 - ETA: 5s - loss: 0.0994 - acc: 0.877 - ETA: 5s - loss: 0.0977 - acc: 0.879 - ETA: 5s - loss: 0.0976 - acc: 0.879 - ETA: 4s - loss: 0.1006 - acc: 0.875 - ETA: 4s - loss: 0.0997 - acc: 0.877 - ETA: 4s - loss: 0.0986 - acc: 0.878 - ETA: 4s - loss: 0.0978 - acc: 0.879 - ETA: 3s - loss: 0.0951 - acc: 0.883 - ETA: 3s - loss: 0.0969 - acc: 0.880 - ETA: 3s - loss: 0.0998 - acc: 0.876 - ETA: 3s - loss: 0.1010 - acc: 0.874 - ETA: 2s - loss: 0.1009 - acc: 0.875 - ETA: 2s - loss: 0.1036 - acc: 0.872 - ETA: 2s - loss: 0.1039 - acc: 0.871 - ETA: 2s - loss: 0.1068 - acc: 0.867 - ETA: 1s - loss: 0.1051 - acc: 0.868 - ETA: 1s - loss: 0.1047 - acc: 0.868 - ETA: 1s - loss: 0.1035 - acc: 0.870 - ETA: 1s - loss: 0.1024 - acc: 0.872 - ETA: 0s - loss: 0.1031 - acc: 0.871 - ETA: 0s - loss: 0.1026 - acc: 0.872 - ETA: 0s - loss: 0.1005 - acc: 0.874 - ETA: 0s - loss: 0.1015 - acc: 0.872 - 10s 241ms/step - loss: 0.0996 - acc: 0.8753\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - ETA: 7s - loss: 0.0904 - acc: 0.906 - ETA: 8s - loss: 0.1012 - acc: 0.875 - ETA: 8s - loss: 0.1148 - acc: 0.854 - ETA: 8s - loss: 0.1116 - acc: 0.859 - ETA: 8s - loss: 0.0978 - acc: 0.881 - ETA: 7s - loss: 0.0815 - acc: 0.901 - ETA: 7s - loss: 0.0810 - acc: 0.901 - ETA: 7s - loss: 0.0845 - acc: 0.898 - ETA: 6s - loss: 0.0891 - acc: 0.895 - ETA: 6s - loss: 0.0852 - acc: 0.900 - ETA: 6s - loss: 0.0857 - acc: 0.900 - ETA: 6s - loss: 0.0825 - acc: 0.903 - ETA: 6s - loss: 0.0799 - acc: 0.906 - ETA: 6s - loss: 0.0814 - acc: 0.904 - ETA: 5s - loss: 0.0824 - acc: 0.902 - ETA: 5s - loss: 0.0806 - acc: 0.902 - ETA: 5s - loss: 0.0820 - acc: 0.900 - ETA: 5s - loss: 0.0831 - acc: 0.899 - ETA: 4s - loss: 0.0817 - acc: 0.899 - ETA: 4s - loss: 0.0832 - acc: 0.898 - ETA: 4s - loss: 0.0821 - acc: 0.898 - ETA: 4s - loss: 0.0820 - acc: 0.899 - ETA: 4s - loss: 0.0846 - acc: 0.895 - ETA: 3s - loss: 0.0850 - acc: 0.895 - ETA: 3s - loss: 0.0826 - acc: 0.898 - ETA: 3s - loss: 0.0834 - acc: 0.896 - ETA: 3s - loss: 0.0826 - acc: 0.897 - ETA: 2s - loss: 0.0860 - acc: 0.893 - ETA: 2s - loss: 0.0862 - acc: 0.894 - ETA: 2s - loss: 0.0878 - acc: 0.891 - ETA: 2s - loss: 0.0862 - acc: 0.894 - ETA: 1s - loss: 0.0847 - acc: 0.896 - ETA: 1s - loss: 0.0842 - acc: 0.896 - ETA: 1s - loss: 0.0856 - acc: 0.896 - ETA: 1s - loss: 0.0859 - acc: 0.895 - ETA: 0s - loss: 0.0835 - acc: 0.898 - ETA: 0s - loss: 0.0846 - acc: 0.896 - ETA: 0s - loss: 0.0841 - acc: 0.897 - ETA: 0s - loss: 0.0875 - acc: 0.892 - 9s 236ms/step - loss: 0.0875 - acc: 0.8912\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - ETA: 9s - loss: 0.0862 - acc: 0.906 - ETA: 5s - loss: 0.1531 - acc: 0.803 - ETA: 7s - loss: 0.1650 - acc: 0.795 - ETA: 7s - loss: 0.1492 - acc: 0.815 - ETA: 7s - loss: 0.1375 - acc: 0.833 - ETA: 7s - loss: 0.1306 - acc: 0.835 - ETA: 7s - loss: 0.1264 - acc: 0.841 - ETA: 7s - loss: 0.1184 - acc: 0.853 - ETA: 7s - loss: 0.1101 - acc: 0.862 - ETA: 7s - loss: 0.1099 - acc: 0.860 - ETA: 6s - loss: 0.1020 - acc: 0.870 - ETA: 6s - loss: 0.0968 - acc: 0.876 - ETA: 6s - loss: 0.0962 - acc: 0.876 - ETA: 6s - loss: 0.0978 - acc: 0.875 - ETA: 6s - loss: 0.1025 - acc: 0.869 - ETA: 5s - loss: 0.1015 - acc: 0.871 - ETA: 5s - loss: 0.1017 - acc: 0.870 - ETA: 5s - loss: 0.1007 - acc: 0.872 - ETA: 5s - loss: 0.1000 - acc: 0.874 - ETA: 4s - loss: 0.0991 - acc: 0.870 - ETA: 4s - loss: 0.1020 - acc: 0.866 - ETA: 4s - loss: 0.1001 - acc: 0.869 - ETA: 4s - loss: 0.0984 - acc: 0.870 - ETA: 3s - loss: 0.1000 - acc: 0.868 - ETA: 3s - loss: 0.0974 - acc: 0.872 - ETA: 3s - loss: 0.0964 - acc: 0.873 - ETA: 3s - loss: 0.0967 - acc: 0.873 - ETA: 2s - loss: 0.0977 - acc: 0.872 - ETA: 2s - loss: 0.0954 - acc: 0.876 - ETA: 2s - loss: 0.0948 - acc: 0.877 - ETA: 2s - loss: 0.0956 - acc: 0.877 - ETA: 1s - loss: 0.0949 - acc: 0.877 - ETA: 1s - loss: 0.0939 - acc: 0.879 - ETA: 1s - loss: 0.0933 - acc: 0.879 - ETA: 1s - loss: 0.0943 - acc: 0.877 - ETA: 0s - loss: 0.0954 - acc: 0.875 - ETA: 0s - loss: 0.0951 - acc: 0.875 - ETA: 0s - loss: 0.0928 - acc: 0.879 - ETA: 0s - loss: 0.0920 - acc: 0.880 - 10s 240ms/step - loss: 0.0918 - acc: 0.8805\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - ETA: 9s - loss: 0.0896 - acc: 0.875 - ETA: 9s - loss: 0.1149 - acc: 0.859 - ETA: 9s - loss: 0.1001 - acc: 0.875 - ETA: 9s - loss: 0.0931 - acc: 0.882 - ETA: 8s - loss: 0.0937 - acc: 0.881 - ETA: 8s - loss: 0.0884 - acc: 0.885 - ETA: 8s - loss: 0.0922 - acc: 0.883 - ETA: 8s - loss: 0.0972 - acc: 0.878 - ETA: 7s - loss: 0.0957 - acc: 0.881 - ETA: 7s - loss: 0.0931 - acc: 0.884 - ETA: 7s - loss: 0.0901 - acc: 0.886 - ETA: 7s - loss: 0.0940 - acc: 0.882 - ETA: 6s - loss: 0.0975 - acc: 0.879 - ETA: 6s - loss: 0.0934 - acc: 0.883 - ETA: 6s - loss: 0.0935 - acc: 0.883 - ETA: 5s - loss: 0.0860 - acc: 0.893 - ETA: 5s - loss: 0.0857 - acc: 0.894 - ETA: 5s - loss: 0.0856 - acc: 0.894 - ETA: 4s - loss: 0.0858 - acc: 0.893 - ETA: 4s - loss: 0.0856 - acc: 0.892 - ETA: 4s - loss: 0.0861 - acc: 0.892 - ETA: 4s - loss: 0.0855 - acc: 0.892 - ETA: 3s - loss: 0.0884 - acc: 0.889 - ETA: 3s - loss: 0.0868 - acc: 0.891 - ETA: 3s - loss: 0.0874 - acc: 0.890 - ETA: 3s - loss: 0.0907 - acc: 0.886 - ETA: 2s - loss: 0.0905 - acc: 0.887 - ETA: 2s - loss: 0.0898 - acc: 0.886 - ETA: 2s - loss: 0.0885 - acc: 0.887 - ETA: 2s - loss: 0.0876 - acc: 0.889 - ETA: 1s - loss: 0.0871 - acc: 0.889 - ETA: 1s - loss: 0.0871 - acc: 0.890 - ETA: 1s - loss: 0.0916 - acc: 0.884 - ETA: 1s - loss: 0.0919 - acc: 0.884 - ETA: 0s - loss: 0.0924 - acc: 0.883 - ETA: 0s - loss: 0.0911 - acc: 0.884 - ETA: 0s - loss: 0.0908 - acc: 0.883 - ETA: 0s - loss: 0.0901 - acc: 0.884 - 10s 241ms/step - loss: 0.0909 - acc: 0.8832\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - ETA: 10s - loss: 0.0761 - acc: 0.90 - ETA: 9s - loss: 0.1210 - acc: 0.8594 - ETA: 9s - loss: 0.1025 - acc: 0.885 - ETA: 9s - loss: 0.0997 - acc: 0.890 - ETA: 9s - loss: 0.1116 - acc: 0.875 - ETA: 8s - loss: 0.0999 - acc: 0.885 - ETA: 8s - loss: 0.0982 - acc: 0.888 - ETA: 8s - loss: 0.0950 - acc: 0.890 - ETA: 7s - loss: 0.0881 - acc: 0.899 - ETA: 7s - loss: 0.0881 - acc: 0.896 - ETA: 7s - loss: 0.0968 - acc: 0.886 - ETA: 6s - loss: 0.0930 - acc: 0.887 - ETA: 6s - loss: 0.0907 - acc: 0.888 - ETA: 6s - loss: 0.0880 - acc: 0.892 - ETA: 6s - loss: 0.0886 - acc: 0.893 - ETA: 5s - loss: 0.0908 - acc: 0.890 - ETA: 5s - loss: 0.0928 - acc: 0.887 - ETA: 5s - loss: 0.0891 - acc: 0.890 - ETA: 5s - loss: 0.0890 - acc: 0.891 - ETA: 4s - loss: 0.0850 - acc: 0.896 - ETA: 4s - loss: 0.0860 - acc: 0.894 - ETA: 4s - loss: 0.0865 - acc: 0.893 - ETA: 4s - loss: 0.0903 - acc: 0.888 - ETA: 3s - loss: 0.0901 - acc: 0.889 - ETA: 3s - loss: 0.0928 - acc: 0.884 - ETA: 3s - loss: 0.0928 - acc: 0.884 - ETA: 3s - loss: 0.0921 - acc: 0.885 - ETA: 2s - loss: 0.0911 - acc: 0.887 - ETA: 2s - loss: 0.0902 - acc: 0.888 - ETA: 2s - loss: 0.0955 - acc: 0.882 - ETA: 2s - loss: 0.0971 - acc: 0.879 - ETA: 1s - loss: 0.0942 - acc: 0.883 - ETA: 1s - loss: 0.0968 - acc: 0.879 - ETA: 1s - loss: 0.0958 - acc: 0.881 - ETA: 1s - loss: 0.0959 - acc: 0.881 - ETA: 0s - loss: 0.0951 - acc: 0.882 - ETA: 0s - loss: 0.0941 - acc: 0.883 - ETA: 0s - loss: 0.0945 - acc: 0.883 - ETA: 0s - loss: 0.0929 - acc: 0.885 - 10s 244ms/step - loss: 0.0951 - acc: 0.8823\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"d:/data/preprocessed_dataset/alexnet.h5\")\n",
    "base_model = Model(img_input, out)\n",
    "base_model.set_weights(model.get_weights())\n",
    "for l in range(len(base_model.layers) - 2):\n",
    "    base_model.layers[l].trainable = False   \n",
    "\n",
    "im_in = Input(shape=(224, 224, 3))\n",
    "x1 = base_model([im_in])\n",
    "\n",
    "model_top = Model(inputs=[im_in], outputs=x1)\n",
    "# model_top.load_weights(\"d:/data/preprocessed_dataset/siam_alex.h5\")\n",
    "model_top.summary()\n",
    "\n",
    "left_input = Input(shape=(224, 224, 3))\n",
    "right_input = Input(shape=(224, 224, 3))\n",
    "\n",
    "h1 = model_top(left_input)\n",
    "h2 = model_top(right_input)\n",
    "\n",
    "distance = Lambda(euclidean_distance)([h1, h2])\n",
    "siam_model = Model(inputs=[left_input, right_input], outputs=distance)\n",
    "siam_model.compile(loss='mse', optimizer=SGD(0.001), metrics=['acc'])\n",
    "siam_model.summary()\n",
    "callback_list = [EarlyStopping(monitor='acc', patience=3),\n",
    "                 ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2)]\n",
    "output = siam_model.fit_generator(train_gen, steps_per_epoch=40, epochs=10,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## siam model    load err: axes doesn't match ##\n",
    "''' model  , load weight '''\n",
    "model_json = model_top.to_json()\n",
    "with open(\"d:/data/preprocessed_dataset/siam_alex.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model_top.save_weights(\"d:/data/preprocessed_dataset/siam_alex.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 96)        34848     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 56, 56, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 256)       614400    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 27, 27, 384)       884736    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 27, 27, 384)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 384)       1327104   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 256)       884736    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 4097      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,802,593\n",
      "Trainable params: 4,802,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = load_model(\"d:/data/preprocessed_dataset/alexnet.h5\")\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions50_1 = model_1.predict_generator(test50_generator, steps=len(test50_generator))\n",
    "y_pred50_1 = predictions50_1.copy()\n",
    "predictions50_1[predictions50_1 > 0.5] = 1\n",
    "predictions50_1[predictions50_1 <= 0.5] = 0\n",
    "true_classes50_1 = test50_generator.classes\n",
    "\n",
    "fpr50_1, tpr50_1, thresholds50_1 = roc_curve(true_classes50_1, y_pred50_1, pos_label=1.)\n",
    "cm50_1 = confusion_matrix(true_classes50_1, predictions50_1)\n",
    "recall50_1 = cm50_1[0][0] / (cm50_1[0][0] + cm50_1[0][1])\n",
    "fallout50_1 = cm50_1[1][0] / (cm50_1[1][0] + cm50_1[1][1])\n",
    "eer50_1 = brentq(lambda x : 1. - x - interp1d(fpr50_1, tpr50_1)(x), 0., 1.)\n",
    "thresh50_1 = interp1d(fpr50_1, thresholds50_1)(eer50_1)\n",
    "test_loss50_1, test_acc50_1 = model_1.evaluate_generator(test50_generator, steps=len(test50_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.48      0.49     16543\n",
      "           1       0.50      0.52      0.51     16543\n",
      "\n",
      "   micro avg       0.50      0.50      0.50     33086\n",
      "   macro avg       0.50      0.50      0.50     33086\n",
      "weighted avg       0.50      0.50      0.50     33086\n",
      "\n",
      "FPR=FAR 0.48231880553708517\n",
      "FNR=FRR 0.5201595841141269\n",
      "test acc: 0.9811098349502972\n",
      "test_loss: 0.06298309940407233\n",
      "thresh: 0.9337399005889906\n",
      "eer: 0.5015414374659964\n",
      "[[7938 8605]\n",
      " [7979 8564]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(true_classes50_1, predictions50_1))\n",
    "print(\"FPR=FAR\", fallout50_1)\n",
    "print(\"FNR=FRR\", 1-recall50_1)\n",
    "print('test acc:', test_acc50_1)\n",
    "print('test_loss:', test_loss50_1)\n",
    "print('thresh:', thresh50_1)\n",
    "print('eer:', eer50_1)\n",
    "print(cm50_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16942it [03:19, 86.55it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-7926d18ef224>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest50_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0my_score50_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msiam_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mscore50_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score50_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0manswer50_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1272\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1274\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score50_2 = []\n",
    "answer50_2 = []\n",
    "max_iter50_2 = int(20000)\n",
    "j = 0\n",
    "for i in tqdm(test50_gen):\n",
    "    y_score50_2 = siam_model.predict_on_batch(i[0])\n",
    "    score50_2.append(y_score50_2)\n",
    "    answer50_2.append(i[1])\n",
    "    j += 1\n",
    "    \n",
    "score50_2 = np.concatenate(score50_2)\n",
    "answer50_2 = np.concatenate(answer50_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat50_2 = score50_2.copy()\n",
    "y_hat50_2[y_hat50_2 >= 0.9] = 1.\n",
    "y_hat50_2[y_hat50_2 < 0.9] = 0.\n",
    "\n",
    "cm50_2 = confusion_matrix(answer50_2, y_hat50_2)\n",
    "recall50_2 = cm50_2[0][0] / (cm50_2[0][0] + cm50_2[0][1])\n",
    "fallout50_2 = cm50_2[1][0] / (cm50_2[1][0] + cm50_2[1][1])\n",
    "fpr50_2, tpr50_2, thresholds50_2 = roc_curve(answer50_2, score50_2, pos_label=1.)\n",
    "thresh = interp1d(fpr50_2, thresholds50_2)(eer50_2)\n",
    "eer50_2 = brentq(lambda x : 1. - x - interp1d(fpr50_2, tpr50_2)(x), 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(answer50_2, y_hat50_2))\n",
    "print(confusion_matrix(answer50_2, y_hat50_2))\n",
    "print(\"FPR=FAR\", fallout50_2)\n",
    "print(\"FNR=FRR\", 1-recall50_2)\n",
    "print('test_acc: ', len(y_hat50_2[np.equal(y_hat50_2, answer50_2)]) / len(y_hat50_2)\n",
    "  print('thresh:', thresh50_2)\n",
    "print('eer:', eer50_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model - 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions75_1 = model_1.predict_generator(test75_generator, steps=len(test75_generator))\n",
    "y_pred75_1 = predictions75_1.copy()\n",
    "predictions75_1[predictions75_1 > 0.5] = 1\n",
    "predictions75_1[predictions75_1 <= 0.5] = 0\n",
    "true_classes75_1 = test75_generator.classes\n",
    "\n",
    "fpr75_1, tpr75_1, thresholds75_1 = roc_curve(true_classes75_1, y_pred75_1, pos_label=1.)\n",
    "cm75_1 = confusion_matrix(true_classes75_1, predictions75_1)\n",
    "recall75_1 = cm75_1[0][0] / (cm75_1[0][0] + cm75_1[0][1])\n",
    "fallout75_1 = cm75_1[1][0] / (cm75_1[1][0] + cm75_1[1][1])\n",
    "eer75_1 = brentq(lambda x : 1. - x - interp1d(fpr75_1, tpr75_1)(x), 0., 1.)\n",
    "thresh75_1 = interp1d(fpr75_1, thresholds75_1)(eer75_1)\n",
    "test_loss75_1, test_acc75_1 = model_1.evaluate_generator(test75_generator, steps=len(test75_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(true_classes75_1, predictions75_1))\n",
    "print(\"FPR=FAR\", fallout75_1)\n",
    "print(\"FNR=FRR\", 1-recall75_1)\n",
    "print('test acc:', test_acc75_1)\n",
    "print('test_loss:', test_loss75_1)\n",
    "print('thresh:', thresh75_1)\n",
    "print('eer:', eer75_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score75_2 = []\n",
    "answer75_2 = []\n",
    "max_iter75_2 = int(20000)\n",
    "j = 0\n",
    "for i in tqdm(test75_gen):\n",
    "    y_score75_2 = siam_model.predict_on_batch(i[0])\n",
    "    score75_2.append(y_score75_2)\n",
    "    answer75_2.append(i[1])\n",
    "    j += 1\n",
    "    \n",
    "score75_2 = np.concatenate(score75_2)\n",
    "answer75_2 = np.concatenate(answer75_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(answer75_2, y_hat75_2))\n",
    "print(confusion_matrix(answer75_2, y_hat75_2))\n",
    "print(\"FPR=FAR\", fallout75_2)\n",
    "print(\"FNR=FRR\", 1-recall75_2)\n",
    "print('test_acc: ', len(y_hat75_2[np.equal(y_hat75_2, answer75_2)]) / len(y_hat75_2)\n",
    "  print('thresh:', thresh75_2)\n",
    "print('eer:', eer75_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model - 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions95_1 = model_1.predict_generator(test95_generator, steps=len(test95_generator))\n",
    "y_pred95_1 = predictions95_1.copy()\n",
    "predictions95_1[predictions95_1 > 0.5] = 1\n",
    "predictions95_1[predictions95_1 <= 0.5] = 0\n",
    "true_classes95_1 = test95_generator.classes\n",
    "\n",
    "fpr95_1, tpr95_1, thresholds95_1 = roc_curve(true_classes95_1, y_pred95_1, pos_label=1.)\n",
    "cm95_1 = confusion_matrix(true_classes95_1, predictions95_1)\n",
    "recall95_1 = cm95_1[0][0] / (cm95_1[0][0] + cm95_1[0][1])\n",
    "fallout95_1 = cm95_1[1][0] / (cm95_1[1][0] + cm95_1[1][1])\n",
    "eer95_1 = brentq(lambda x : 1. - x - interp1d(fpr95_1, tpr95_1)(x), 0., 1.)\n",
    "thresh95_1 = interp1d(fpr95_1, thresholds95_1)(eer95_1)\n",
    "test_loss95_1, test_acc95_1 = model_1.evaluate_generator(test95_generator, steps=len(test95_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(true_classes95_1, predictions95_1))\n",
    "print(\"FPR=FAR\", fallout95_1)\n",
    "print(\"FNR=FRR\", 1-recall95_1)\n",
    "print('test acc:', test_acc95_1)\n",
    "print('test_loss:', test_loss95_1)\n",
    "print('thresh:', thresh95_1)\n",
    "print('eer:', eer95_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score95_2 = []\n",
    "answer95_2 = []\n",
    "max_iter95_2 = int(20000)\n",
    "j = 0\n",
    "for i in tqdm(test95_gen):\n",
    "    y_score95_2 = siam_model.predict_on_batch(i[0])\n",
    "    score95_2.append(y_score95_2)\n",
    "    answer95_2.append(i[1])\n",
    "    j += 1\n",
    "    \n",
    "score95_2 = np.concatenate(score95_2)\n",
    "answer95_2 = np.concatenate(answer95_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(answer95_2, y_hat95_2))\n",
    "print(confusion_matrix(answer95_2, y_hat95_2))\n",
    "print(\"FPR=FAR\", fallout95_2)\n",
    "print(\"FNR=FRR\", 1-recall95_2)\n",
    "print('test_acc: ', len(y_hat95_2[np.equal(y_hat95_2, answer95_2)]) / len(y_hat95_2)\n",
    "  print('thresh:', thresh95_2)\n",
    "print('eer:', eer95_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(fpr50_1, tpr50_1, 'b-', label=\"AlexNet (50%)\")\n",
    "plt.plot(fpr50_2, tpr50_2, 'r-', label=\"Siamese(Ours) (50%)\")\n",
    "plt.plot(fpr75_1, tpr75_1, 'b-', label=\"AlexNet (75%)\")\n",
    "plt.plot(fpr75_2, tpr75_2, 'r-', label=\"Siamese(Ours) (75%)\")\n",
    "plt.plot(fpr95_1, tpr95_1, 'b-', label=\"AlexNet (95%)\")\n",
    "plt.plot(fpr95_2, tpr95_2, 'r-', label=\"Siamese(Ours) (95%)\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"random guess\")\n",
    "plt.plot([fallout], [recall], 'ro', ms=10)\n",
    "plt.plot([fallout1], [recall1], 'bo', ms=10)\n",
    "plt.xlabel('False Positive Rate (Fall-Out)')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title(\"Best AUROC: %.3f / Model: Ours\" %(roc_auc_score(answer, score)))\n",
    "plt.legend(loc='lower right')\n",
    "# plt.annotate(\"%.3f: AlexNet\" %(roc_auc_score(true_classes, y_pred)), xy=(0.88, 0.85), xytext=(0.75, 0.70), arrowprops={'color':'blue'})\n",
    "# plt.annotate(\"%.3f: Ours\" %(roc_auc_score(answer, score)), xy=(0.0, 0.99), xytext=(0.15, 0.9), arrowprops={'color':'red'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
